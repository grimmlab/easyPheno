{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HowTo: Use easyPheno as a pip package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this Jupyter notebook, we show how you can use easyPheno as a pip package and also guide you through the steps that easyPheno is doing when triggering an optimization run.\n",
    "\n",
    "Please clone the whole GitHub repository if you want to run this tutorial on your own, as we need the tutorial data from our GitHub repository and to make sure that all paths we define are correct: ``git clone https://github.com/grimmlab/easyPheno.git``\n",
    "\n",
    "Then, start a Jupyter notebook server on your machine and open this Jupyter notebook, which is placed at ``docs/source/tutorials`` in the repository.\n",
    "\n",
    "However, you could also download the single files and define the paths yourself:\n",
    "\n",
    "- The Jupyter notebook can be downloaded here: [HowTo: Use easyPheno as a pip package.ipynb](https://github.com/grimmlab/easyPheno/tree/main/docs/source/tutorials/HowTo%20Use%20easyPheno%20as%20a%20pip%20package.ipynb)\n",
    "\n",
    "- The data we use can be found here: [tutorial data](https://github.com/grimmlab/easyPheno/tree/main/docs/source/tutorials/tutorial_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Installation, imports and paths\n",
    "First, we may need to install easyPheno (uncomment if it is not already installed). Then, we import easyPheno as well as further libraries that we need in this tutorial. In the end, we define some paths and filenames which we will use more often throughout this tutorial. We will save the results in the same directory where this repository is placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip3 install easypheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import easypheno\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Definition of paths and filenames\n",
    "cwd = pathlib.Path.cwd()\n",
    "data_dir = cwd.joinpath('tutorial_data')\n",
    "save_dir = cwd.parents[3]\n",
    "genotype_matrix = 'x_matrix.csv'\n",
    "phenotype_matrix = 'y_matrix.csv'\n",
    "phenotype = 'continuous_values'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run whole optimization pipeline at once\n",
    "As shown for the [Docker workflow](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html), easyPheno offers a function [optim_pipeline.run()](https://github.com/grimmlab/easyPheno/blob/main/easypheno/optim_pipeline.py) that triggers the whole optimization run. \n",
    "\n",
    "In the definition of ``optim_pipeline.run()``, we set several default values. In order to run it using our tutorial data, we just need to define the data and directories we want to use as well as the models we want to optimize. Furthermore, we set values for the ``datasplit`` and ``n_trials`` to limit the waiting time for getting the results.\n",
    "\n",
    "When calling the function, we first see some information regarding the data preprocessing and the configuration of our optimization run, e.g. the data that is used. Then, the current progress of the optuna optimization with results of the individual trials is shown. In the end, we show a summary of the whole optimization run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if all data files have the required format\n",
      "Genotype file not in required format. Will load genotype matrix and save as .h5 file. Will also create required index file.\n",
      "Load genotype file /home/fhaselbeck/PycharmProjects/easyPheno/docs/source/tutorials/tutorial_data/x_matrix.csv\n",
      "Save unified genotype file /home/fhaselbeck/PycharmProjects/easyPheno/docs/source/tutorials/tutorial_data/x_matrix.h5\n",
      "Have genotype matrix. Load phenotype continuous_values from /home/fhaselbeck/PycharmProjects/easyPheno/docs/source/tutorials/tutorial_data/y_matrix.csv\n",
      "Have phenotype vector. Start matching genotype and phenotype.\n",
      "Done matching genotype and phenotype. Create index file now.\n",
      "Done checking data files. All required datasets are available.\n",
      "----- Starting dataset preparation -----\n",
      "Load and match raw data\n",
      "Apply MAF filter\n",
      "Filter duplicate SNPs\n",
      "Check if final snp_ids already exist in index_file for used encoding and maf percentage. Save them if necessary.\n",
      "Load datasplit file\n",
      "Checked datasplit for all folds.\n",
      "+++++++++++ CONFIG INFORMATION +++++++++++\n",
      "Genotype Matrix: x_matrix.csv\n",
      "Phenotype Matrix: y_matrix.csv\n",
      "Phenotype: continuous_values\n",
      "Encoding: 012\n",
      "Models: xgboost\n",
      "Optuna Trials: 10\n",
      "Datasplit: cv-test (5-20)\n",
      "MAF: 0\n",
      "Dataset Infos\n",
      "- Task detected: regression\n",
      "- No. of samples: 286, No. of features: 590\n",
      "- Encoding: 012\n",
      "- Target variable statistics: \n",
      "count    286.000000\n",
      "mean      84.542832\n",
      "std       20.141244\n",
      "min       53.000000\n",
      "25%       69.250000\n",
      "50%       78.750000\n",
      "75%       97.750000\n",
      "max      157.500000\n",
      "Name: 0, dtype: float64\n",
      "++++++++++++++++++++++++++++++++++++++++++++\n",
      "### Starting Optuna Optimization for xgboost ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:07:07,575]\u001B[0m A new study created in RDB with name: 2022-10-04_16-07-04_x_matrix-y_matrix-continuous_values-MAF0-SPLITcv-test5-20-MODELxgboost-TRIALS10\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 0\n",
      "{'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:07:15,020]\u001B[0m Trial 0 finished with value: 369.22728277444065 and parameters: {'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 1\n",
      "{'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:07:25,321]\u001B[0m Trial 1 finished with value: 454.8753047090302 and parameters: {'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 2\n",
      "{'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:07:32,860]\u001B[0m Trial 2 finished with value: 398.20160514328586 and parameters: {'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 3\n",
      "{'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:07:41,691]\u001B[0m Trial 3 finished with value: 369.6724074334373 and parameters: {'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 4\n",
      "{'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:07:49,667]\u001B[0m Trial 4 finished with value: 364.574017351775 and parameters: {'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 5\n",
      "{'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:01,195]\u001B[0m Trial 5 finished with value: 452.7427816744316 and parameters: {'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 6\n",
      "{'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:06,452]\u001B[0m Trial 6 finished with value: 447.1631958152293 and parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 7\n",
      "{'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:10,461]\u001B[0m Trial 7 finished with value: 420.049507545245 and parameters: {'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 8\n",
      "{'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:19,589]\u001B[0m Trial 8 finished with value: 373.9128450040709 and parameters: {'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 9\n",
      "{'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:28,648]\u001B[0m Trial 9 finished with value: 419.9258576836199 and parameters: {'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Optuna Study finished ##\n",
      "Study statistics: \n",
      "  Finished trials:  10\n",
      "  Pruned trials:  0\n",
      "  Completed trials:  10\n",
      "  Best Trial:  4\n",
      "  Value:  364.574017351775\n",
      "  Params: \n",
      "    colsample_bytree: 0.05\n",
      "    gamma: 520\n",
      "    learning_rate: 0.25\n",
      "    max_depth: 6\n",
      "    n_estimators: 1750\n",
      "    reg_alpha: 100.0\n",
      "    subsample: 0.35000000000000003\n",
      "## Retrain best model and test ##\n",
      "## Results on test set ##\n",
      "{'test_mse': 393.8179197745938, 'test_rmse': 19.84484617664228, 'test_r2_score': 0.05719242798046553, 'test_explained_variance': 0.05724940832753167}\n",
      "### Finished Optuna Optimization for xgboost ###\n",
      "# Optimization runs done for models ['xgboost']\n",
      "Results overview on the test set(s)\n",
      "{'xgboost': {'Test': {'best_params': {'colsample_bytree': 0.05,\n",
      "                                      'gamma': 520,\n",
      "                                      'learning_rate': 0.25,\n",
      "                                      'max_depth': 6,\n",
      "                                      'n_estimators': 1750,\n",
      "                                      'reg_alpha': 100.0,\n",
      "                                      'subsample': 0.35000000000000003},\n",
      "                      'eval_metrics': {'test_explained_variance': 0.05724940832753167,\n",
      "                                       'test_mse': 393.8179197745938,\n",
      "                                       'test_r2_score': 0.05719242798046553,\n",
      "                                       'test_rmse': 19.84484617664228},\n",
      "                      'runtime_metrics': {'process_time_max': 36.719140110000005,\n",
      "                                          'process_time_mean': 20.092465339700002,\n",
      "                                          'process_time_min': 1.2973512780000078,\n",
      "                                          'process_time_std': 13.062248523467469,\n",
      "                                          'real_time_max': 10.839427947998049,\n",
      "                                          'real_time_mean': 7.2125649690628055,\n",
      "                                          'real_time_min': 3.837096929550171,\n",
      "                                          'real_time_std': 2.0072883008924216}}}}\n"
     ]
    }
   ],
   "source": [
    "easypheno.optim_pipeline.run(\n",
    "    data_dir=data_dir, genotype_matrix=genotype_matrix, phenotype_matrix=phenotype_matrix, phenotype=phenotype,\n",
    "    save_dir=save_dir, models=['xgboost'], n_trials=10, datasplit='cv-test'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Within the defined ``save_dir``, a ``results`` folder will be created. \n",
    "   \n",
    "Then, easyPheno's default folder structure follows: ``name_of_genotype_matrix/name_of_phenotype_matrix/phenotype/``. For instance, all phenotype matrices assigned to the same genotype matrix are gathered in the same subdirectory (``name_of_genotype_matrix/``). The same applies for all phenotypes assigned to the same phenotype matirx (``name_of_genotype_matrix/name_of_phenotype_matrix/``)\n",
    "\n",
    "We can see this structure below with all optimization results for the defined ``phenotype``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04\n"
     ]
    }
   ],
   "source": [
    "result_folders = list(save_dir.joinpath('results', genotype_matrix.split('.')[0], phenotype_matrix.split('.')[0], phenotype).glob('*'))\n",
    "for results_dir in result_folders:\n",
    "    print(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "These result folder names show information on the ``datasplit`` (type and parameters, e.g. in case of ``cv-test`` the part ``5-20`` 5 relates to 5 folds of the cross-validation and 20 to a test set consisting of 20 percent of the data). Furthermore, we see the maf filter that was applied (``MAF``), the ``models`` that were optimized and a time stamp.\n",
    "\n",
    "In the example below, we can see that each result folder contains a ``Results_overview_*.csv`` as well as detailed results for each of the optimized models. In case of ``nested-cv``, this is preceded by a subfolder for each of the outer folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/Results_overview_xgboost.csv\n"
     ]
    }
   ],
   "source": [
    "result_elements = list(result_folders[0].glob('*'))\n",
    "for result_element in result_elements:\n",
    "    print(result_element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The ``Results_overview_*.csv`` file contains the best parameters, evaluation as well as runtime metrics for each of the optimized models as we can see in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>xgboost___best_params</th>\n",
       "      <th>xgboost___eval_metrics</th>\n",
       "      <th>xgboost___runtime_metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test</td>\n",
       "      <td>[{'colsample_bytree': 0.05, 'gamma': 520, 'lea...</td>\n",
       "      <td>[{'test_mse': 393.8179197745938, 'test_rmse': ...</td>\n",
       "      <td>[{'process_time_mean': 20.092465339700002, 'pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0                              xgboost___best_params  \\\n",
       "0       Test  [{'colsample_bytree': 0.05, 'gamma': 520, 'lea...   \n",
       "\n",
       "                              xgboost___eval_metrics  \\\n",
       "0  [{'test_mse': 393.8179197745938, 'test_rmse': ...   \n",
       "\n",
       "                           xgboost___runtime_metrics  \n",
       "0  [{'process_time_mean': 20.092465339700002, 'pr...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_overview_file = [overview_file for overview_file in result_elements if 'Results_overview' in str(overview_file)][0]\n",
    "pd.read_csv(results_overview_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Beyond that, we see below that the detailed results for each optimized model contain validation and test results, saved prediction models, an optuna database, a runtime overview with information for each trial (good for debugging, as pruning reasons are also documented) and for some prediction models also feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost/Optuna_DB.db\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost/validation_results_trial4.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost/xgboost_runtime_overview.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost/unfitted_model_trial4\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost/final_model_test_results.csv\n",
      "/home/fhaselbeck/PycharmProjects/results/x_matrix/y_matrix/continuous_values/cv-test_5-20_MAF0_xgboost_2022-10-04_16-07-04/xgboost/final_model_feature_importances.csv\n"
     ]
    }
   ],
   "source": [
    "for subdir in [overview_file for overview_file in result_elements if 'Results_overview' not in str(overview_file)][0].rglob('*'):\n",
    "    print(subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Single elements of the optimization pipeline\n",
    "For a better understanding of the whole optimization pipeline, we subsequently show some of the single elements which are called within ``optim_pipeline.run()``. \n",
    "\n",
    "First, ``optim_pipeline.run()`` contains some functions to check the specified arguments, which we will skip for this tutorial. However, we need to define some of the default values and create ``pathlib.Path`` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path(data_dir)\n",
    "save_dir = pathlib.Path(save_dir)\n",
    "datasplit = 'cv-test'\n",
    "n_innerfolds = 5\n",
    "test_set_size_percentage=20\n",
    "maf_percentage = 0\n",
    "models = ['xgboost']\n",
    "n_trials = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first step of the optimization pipeline is the preparation of the raw data files using ``easypheno.preprocess.raw_data_functions.prepare_data_files()``. If the format matches our [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html#), the raw data files are preprocessed.\n",
    "\n",
    "The genotype matrix is converted and unified to a ``.h5`` file and saved with the same name as the raw file, if this genotype matrix is used for the first time. \n",
    "\n",
    "The phenotype matirx is checked whether the format is fine, but not saved in a different format.\n",
    "\n",
    "An index file containing indices for filtering the data (e.g. maf or duplicates) and creating the data splits is saved or updated in case it already exists and a datasplit that is currently not present in the file is requested. This ensures reproducibility of the preprocessing and data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if all data files have the required format\n",
      "Found same file name with ending .h5\n",
      "Assuming that the raw file was already prepared using our pipepline. Will continue with the .h5 file.\n",
      "Genotype file available in required format, check index file now.\n",
      "Index file x_matrix-y_matrix-continuous_values.h5 already exists. Will append required filters and data splits now.\n",
      "Done checking data files. All required datasets are available.\n"
     ]
    }
   ],
   "source": [
    "easypheno.preprocess.raw_data_functions.prepare_data_files(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    models=models, user_encoding=None, maf_percentage=maf_percentage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After setting all seeds for reproducibility using ``easypheno.utils.helper_functions.set_all_seeds()``, a model for the current optimization is selected. This information is then used to retrieve its ``standard_encoding`` if the user did not define an encoding. \n",
    "\n",
    "With this information, the ``easypheno.preprocess.base_dataset.Dataset`` object is initialized.  \n",
    "We also print some information regarding the current progress, as loading the data might take some time for bigger datasets.   \n",
    "When running the optimization for multiple models, these are sorted according to their encoding and the dataset is only loaded new if the encoding changes between models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and match raw data\n",
      "Apply MAF filter\n",
      "Filter duplicate SNPs\n",
      "Check if final snp_ids already exist in index_file for used encoding and maf percentage. Save them if necessary.\n",
      "Load datasplit file\n",
      "Checked datasplit for all folds.\n"
     ]
    }
   ],
   "source": [
    "easypheno.utils.helper_functions.set_all_seeds()\n",
    "current_model_name = models[0]\n",
    "encoding = easypheno.utils.helper_functions.get_mapping_name_to_class()[current_model_name].standard_encoding\n",
    "\n",
    "dataset = easypheno.preprocess.base_dataset.Dataset(\n",
    "    data_dir=data_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, datasplit=datasplit, n_outerfolds=5, n_innerfolds=n_innerfolds,\n",
    "    test_set_size_percentage=test_set_size_percentage, val_set_size_percentage=20,\n",
    "    encoding=encoding, maf_percentage=maf_percentage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "After retrieving the type of ML ``task`` using ``easypheno.utils.helper_functions.test_likely_categorical()`` as well as the time stamp for saving the results, we create an ``easypheno.optimization.optuna_optim.OptunaOptim`` object. For this purpose, we handover all information that is needed for the hyperparameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "task = 'classification' if easypheno.utils.helper_functions.test_likely_categorical(dataset.y_full) else 'regression'\n",
    "models_start_time = '+'.join(models) + '_' + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "optim_run = easypheno.optimization.optuna_optim.OptunaOptim(\n",
    "    save_dir=save_dir, genotype_matrix_name=genotype_matrix, phenotype_matrix_name=phenotype_matrix,\n",
    "    phenotype=phenotype, n_outerfolds=5, n_innerfolds=n_innerfolds,val_set_size_percentage=20, \n",
    "    test_set_size_percentage=test_set_size_percentage, maf_percentage=maf_percentage, n_trials=n_trials, \n",
    "    save_final_model=False, batch_size=None, n_epochs=10000, task=task, \n",
    "    models_start_time=models_start_time, current_model_name=current_model_name, dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we just need to call the method ``run()`` of our ``easypheno.optimization.optuna_optim.OptunaOptim`` object to start the Bayesian hyperparameter search, which will print the current progress and return a dictionary with summary results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:39,294]\u001B[0m A new study created in RDB with name: 2022-10-04_16-08-33_x_matrix-y_matrix-continuous_values-MAF0-SPLITcv-test5-20-MODELxgboost-TRIALS10\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 0\n",
      "{'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:46,932]\u001B[0m Trial 0 finished with value: 369.22728277444065 and parameters: {'n_estimators': 2500, 'learning_rate': 0.07500000000000001, 'max_depth': 3, 'gamma': 300, 'subsample': 0.45, 'colsample_bytree': 0.35000000000000003, 'reg_alpha': 290.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 1\n",
      "{'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:08:59,323]\u001B[0m Trial 1 finished with value: 454.8753047090302 and parameters: {'n_estimators': 3000, 'learning_rate': 0.3, 'max_depth': 9, 'gamma': 300, 'subsample': 0.1, 'colsample_bytree': 0.55, 'reg_alpha': 440.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 2\n",
      "{'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:11,364]\u001B[0m Trial 2 finished with value: 398.20160514328586 and parameters: {'n_estimators': 2250, 'learning_rate': 0.2, 'max_depth': 10, 'gamma': 80, 'subsample': 0.2, 'colsample_bytree': 0.05, 'reg_alpha': 320.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 3\n",
      "{'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:24,604]\u001B[0m Trial 3 finished with value: 369.6724074334373 and parameters: {'n_estimators': 2000, 'learning_rate': 0.225, 'max_depth': 8, 'gamma': 770, 'subsample': 0.1, 'colsample_bytree': 0.3, 'reg_alpha': 110.0}. Best is trial 0 with value: 369.22728277444065.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 4\n",
      "{'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:31,163]\u001B[0m Trial 4 finished with value: 364.574017351775 and parameters: {'n_estimators': 1750, 'learning_rate': 0.25, 'max_depth': 6, 'gamma': 520, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.05, 'reg_alpha': 100.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 5\n",
      "{'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:40,337]\u001B[0m Trial 5 finished with value: 452.7427816744316 and parameters: {'n_estimators': 2750, 'learning_rate': 0.2, 'max_depth': 9, 'gamma': 810, 'subsample': 0.15000000000000002, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 540.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 6\n",
      "{'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:46,464]\u001B[0m Trial 6 finished with value: 447.1631958152293 and parameters: {'n_estimators': 100, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 520, 'subsample': 0.6000000000000001, 'colsample_bytree': 0.3, 'reg_alpha': 980.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 7\n",
      "{'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:49,729]\u001B[0m Trial 7 finished with value: 420.049507545245 and parameters: {'n_estimators': 50, 'learning_rate': 0.3, 'max_depth': 4, 'gamma': 670, 'subsample': 0.6500000000000001, 'colsample_bytree': 0.2, 'reg_alpha': 730.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 8\n",
      "{'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:09:56,208]\u001B[0m Trial 8 finished with value: 373.9128450040709 and parameters: {'n_estimators': 1000, 'learning_rate': 0.2, 'max_depth': 3, 'gamma': 690, 'subsample': 0.35000000000000003, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 130.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params for Trial 9\n",
      "{'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}\n",
      "# Processing innerfold_0 #\n",
      "# Processing innerfold_1 #\n",
      "# Processing innerfold_2 #\n",
      "# Processing innerfold_3 #\n",
      "# Processing innerfold_4 #\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m[I 2022-10-04 16:10:00,982]\u001B[0m Trial 9 finished with value: 419.9258576836199 and parameters: {'n_estimators': 250, 'learning_rate': 0.125, 'max_depth': 5, 'gamma': 730, 'subsample': 0.7500000000000001, 'colsample_bytree': 0.7500000000000001, 'reg_alpha': 780.0}. Best is trial 4 with value: 364.574017351775.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Optuna Study finished ##\n",
      "Study statistics: \n",
      "  Finished trials:  10\n",
      "  Pruned trials:  0\n",
      "  Completed trials:  10\n",
      "  Best Trial:  4\n",
      "  Value:  364.574017351775\n",
      "  Params: \n",
      "    colsample_bytree: 0.05\n",
      "    gamma: 520\n",
      "    learning_rate: 0.25\n",
      "    max_depth: 6\n",
      "    n_estimators: 1750\n",
      "    reg_alpha: 100.0\n",
      "    subsample: 0.35000000000000003\n",
      "## Retrain best model and test ##\n",
      "## Results on test set ##\n",
      "{'test_mse': 393.8179197745938, 'test_rmse': 19.84484617664228, 'test_r2_score': 0.05719242798046553, 'test_explained_variance': 0.05724940832753167}\n",
      "{'Test': {'best_params': {'colsample_bytree': 0.05,\n",
      "                          'gamma': 520,\n",
      "                          'learning_rate': 0.25,\n",
      "                          'max_depth': 6,\n",
      "                          'n_estimators': 1750,\n",
      "                          'reg_alpha': 100.0,\n",
      "                          'subsample': 0.35000000000000003},\n",
      "          'eval_metrics': {'test_explained_variance': 0.05724940832753167,\n",
      "                           'test_mse': 393.8179197745938,\n",
      "                           'test_r2_score': 0.05719242798046553,\n",
      "                           'test_rmse': 19.84484617664228},\n",
      "          'runtime_metrics': {'process_time_max': 36.19791426699999,\n",
      "                              'process_time_mean': 20.51563152270001,\n",
      "                              'process_time_min': 1.4952742340000214,\n",
      "                              'process_time_std': 13.181602909370394,\n",
      "                              'real_time_max': 11.987335681915283,\n",
      "                              'real_time_mean': 7.454001760482788,\n",
      "                              'real_time_min': 3.102874517440796,\n",
      "                              'real_time_std': 3.14674639916681}}}\n"
     ]
    }
   ],
   "source": [
    "summary_results = optim_run.run_optuna_optimization()\n",
    "pprint.PrettyPrinter(depth=4).pprint(summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Beyond that, ``easypheno.optimization.optuna_optim.OptunaOptim`` creates and saves the ``Results_overview_*.csv`` files, which we show above in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Further information\n",
    "This notebooks shows how the use the easyPheno pip package to run an optimization. Furthermore, we give an overview of the individual steps within ``optim_pipeline.run()``.\n",
    "\n",
    "For more information on specific topcis, see the following links:\n",
    "\n",
    "- [Documentation of the whole package](https://easypheno.readthedocs.io/en/latest/index.html)\n",
    "\n",
    "- [easyPheno's GitHub repository](https://github.com/grimmlab/easyPheno)\n",
    "\n",
    "- Prepare your data according to our format: [Data Guide](https://easypheno.readthedocs.io/en/latest/data.html)\n",
    "\n",
    "- The [Installation Guide](https://easypheno.readthedocs.io/en/latest/install_docker.html) as well as [basic tutorial](https://easypheno.readthedocs.io/en/latest/tutorials/tut_run_docker.html) for the Docker workflow as an alternative\n",
    "\n",
    "- Summarize and analyze prediction results with easyPeno: [HowTo: Summarize prediction results with easyPheno](https://easypheno.readthedocs.io/en/latest/tutorials/tut_sum_results.html)\n",
    "\n",
    "- Several [advanced topics](https://easypheno.readthedocs.io/en/latest/tutorials/tut_adv.html) such as adjusting existing prediction models or creation of new ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}